


import pandas as pd
import numpy as np


train =pd.read_csv('./data/4th-t2/train.csv')
test=pd.read_csv('data/4th-t2/test.csv')


train.shape, test.shape


train.head()


train.info()


train.describe()





# test 샘플 확인 
test.head()





# target 확인
train['Segmentation'].value_counts()


# 결측치 확인(train)
# train.isnull().sum()


# 결측치 확인(test)
# test.isnull().sum()


# type 확인
train.info()


# target(y, label) 값 복사
target = train.pop('Segmentation')
target


train = train.drop("ID", axis=1)
train.head(1)


# test데이터 ID 복사
test_ID = test.pop('ID')


# 수치형 컬럼(train)
# ['ID', 'Age', 'Work_Experience', 'Family_Size', 'Segmentation']
num_cols = ['Age', 'Work_Experience', 'Family_Size']
train = train[num_cols]
train.head(2)


# 수치형 컬럼(test)
test = test[num_cols]
test.head(2)





from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(train, target)
pred = rf.predict(test)
pred


submit=pd.DataFrame({
    'ID':test_ID,
    'segmentation': pred
})
submit


submit.to_csv("submission.csv", index=False)
# Score: 0.30477








train =pd.read_csv('./data/4th-t2/train.csv')
test=pd.read_csv('data/4th-t2/test.csv')


train.head(2)


train.info()


train.describe(include="O") # 범주형(object 타입) 변수들에 대한 요약 통계 





train= pd.get_dummies(train)
test=pd.get_dummies(test)


train.info()


target= train.pop('Segmentation')
target


train= train.drop('ID', axis=1)
train.head(1)


test_ID=test.pop('ID')
test_ID


# 모델 선택 및 학습
from sklearn.ensemble import RandomForestClassifier

rf=RandomForestClassifier()
rf.fit(train,target)
pred=rf.predict(test)
pred


submit= pd.DataFrame({
    'ID':test_ID,
    'Segmentation':pred})
submit


submit.to_csv('submission.csv',index=False)








train =pd.read_csv('./data/4th-t2/train.csv')
test=pd.read_csv('data/4th-t2/test.csv')


train.describe(include='O')


# 범주형 변수
# train.select_dtypes(include='object').columns
# ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score','Var_1']
cat_cols = ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score','Var_1']


## label encoding
## Series.astype('category').cat.codes
train['Gender'] = train['Gender'].astype('category').cat.codes
train['Ever_Married'] = train['Ever_Married'].astype('category').cat.codes
train['Graduated'] = train['Graduated'].astype('category').cat.codes
train['Profession'] = train['Profession'].astype('category').cat.codes
train['Spending_Score'] = train['Spending_Score'].astype('category').cat.codes
train['Var_1'] = train['Var_1'].astype('category').cat.codes
train


## label encoding
test['Gender'] = test['Gender'].astype('category').cat.codes
test['Ever_Married'] = test['Ever_Married'].astype('category').cat.codes
test['Graduated'] = test['Graduated'].astype('category').cat.codes
test['Profession'] = test['Profession'].astype('category').cat.codes
test['Spending_Score'] = test['Spending_Score'].astype('category').cat.codes
test['Var_1'] = test['Var_1'].astype('category').cat.codes
test


# ID, target 처리
target = train.pop('Segmentation')
train = train.drop("ID", axis=1)
test_ID = test.pop('ID')


# 모델 선택
# 하이퍼파라미터 튜닝: max_depth, n_estimators
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(random_state=0, max_depth=7, n_estimators=500)


# 교차 검증
from sklearn.model_selection import cross_val_score
scores = cross_val_score(rf, train, target, scoring='f1_macro', cv=5)
print(scores)
print(scores.mean())


rf.fit(train, target)
pred = rf.predict(test)
pred


submit = pd.DataFrame({
    'ID': test_ID,
    'Segmentation': pred
})
submit.to_csv("submission.csv", index=False)
# Score: 0.32046





import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import f1_score
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split

# 데이터 불러오기
train = pd.read_csv('./data/4th-t2/train.csv')
test = pd.read_csv('./data/4th-t2/test.csv')


# 타겟 분리
target = train.pop('Segmentation')
test_ID = test.pop('ID')
train_ID = train.pop('ID')


cat_cols=train.select_dtypes(include='object').columns
print(cat_cols)


for col in cat_cols:
    le=LabelEncoder()
    le.fit(list(train[col])+list(test[col])) # train+ test 전체 기준으로 인코딩
    train[col]= le.transform(train[col])
    test[col]=le.transform(test[col])


# 결측치 처리 (간단히 평균으로)
train = train.fillna(train.mean(numeric_only=True))
test= test.fillna(test.mean(numeric_only=True))


y= target-1


X_train, X_val, y_train, y_val = train_test_split(train, y, test_size=0.2, random_state=42, stratify=target)


model = XGBClassifier(
    random_state=42,
    use_label_encoder=False,
    eval_metric='mlogloss'
)
model.fit(X_train, y_train)


# 검증 점수
val_pred = model.predict(X_val)
f1 = f1_score(y_val, val_pred, average='macro')
print(f"Validation Macro F1-score: {f1:.4f}")


# 전체 학습 후 test 예측
model.fit(train, y)
pred = model.predict(test)


final_pred= pred+1
# 제출 파일 저장
submit = pd.DataFrame({
    'ID': test_ID,
    'Segmentation': final_pred
})
submit.to_csv('submission.csv', index=False)








train =pd.read_csv('./data/4th-t2/train.csv')
test=pd.read_csv('data/4th-t2/test.csv')


train.describe(include="O") # 범주형(object 타입) 변수들에 대한 요약 통계 

train= pd.get_dummies(train)
test=pd.get_dummies(test)

target = train.pop('Segmentation')
test_ID = test.pop('ID')
train_ID = train.pop('ID')


train.shape, test.shape


# 모델 선택
# 하이퍼파라미터 튜닝: max_depth, n_estimators
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(random_state=0, max_depth=8, n_estimators=800)


# 교차 검증
from sklearn.model_selection import cross_val_score
scores = cross_val_score(rf, train, target, scoring='f1_macro', cv=5)
print(scores)
print(scores.mean())


# 학습
rf.fit(train, target)
pred = rf.predict(test)
pred


submit = pd.DataFrame({
    'ID': test_ID,
    'Segmentation': pred
})
submit.to_csv("submission.csv", index=False)
# Score: 0.32046









